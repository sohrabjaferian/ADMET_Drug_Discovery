{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c54ca55-c5e2-498c-8e60-0588add3248c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdc.single_pred import ADME\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fdb4abd-1d6e-4e5a-b288-cec25a87f43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "100%|█████████████████████████████████████| 82.5k/82.5k [00:00<00:00, 7.08MiB/s]\n",
      "Loading...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "data = ADME(name = 'Caco2_Wang')\n",
    "df = data.get_data()\n",
    "splits = data.get_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "543dd82a-c0b0-4f08-90ed-a1910326936a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = splits['train']\n",
    "valid = splits['valid']\n",
    "test = splits['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5ba1819-02b7-4ad7-b1f6-b910acfc60b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat((train, test, valid), axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e1b2a4d-750d-41cb-95eb-3671dd119c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tdc.benchmark_group import admet_group\n",
    "# group = admet_group(path = 'data/')\n",
    "# predictions_list = []\n",
    "\n",
    "# for seed in [1, 2, 3, 4, 5]:\n",
    "#     benchmark = group.get('Caco2_Wang') \n",
    "#     # all benchmark names in a benchmark group are stored in group.dataset_names\n",
    "#     predictions = {}\n",
    "#     name = benchmark['name']\n",
    "#     train_val, test = benchmark['train_val'], benchmark['test']\n",
    "#     train, valid = group.get_train_valid_split(benchmark = name, split_type = 'default', seed = seed)\n",
    "    \n",
    "#         # --------------------------------------------- # \n",
    "#         #  Train your model using train, valid, test    #\n",
    "#         #  Save test prediction in y_pred_test variable #\n",
    "#         # --------------------------------------------- #\n",
    "        \n",
    "#     predictions[name] = y_pred_test\n",
    "#     predictions_list.append(predictions)\n",
    "\n",
    "# results = group.evaluate_many(predictions_list)\n",
    "# # {'caco2_wang': [6.328, 0.101]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f20fe6a9-5df7-4db3-955a-326be11aec82",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'Drug'\n",
    "\n",
    "# Define the file path for the text file\n",
    "file_path = 'Drug.txt'\n",
    "\n",
    "# Extract the column data\n",
    "column_data = train[column_name]\n",
    "\n",
    "# Write column data to text file\n",
    "column_data.to_csv(file_path, header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2791bcb3-5d10-4fa4-994c-a1cf798a24f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepSMILES version: 1.0.1\n",
      "Converter(rings=True, branches=True)\n",
      "Encoded: OcccO)ccc6)OCccccO)cO)c6))))))CO)C6\n",
      "Decoded: Oc1cc(O)c3c(c1)OC(c2ccc(O)c(O)c2)C(O)C3\n"
     ]
    }
   ],
   "source": [
    "import deepsmiles\n",
    "print(\"DeepSMILES version: %s\" % deepsmiles.__version__)\n",
    "converter = deepsmiles.Converter(rings=True, branches=True)\n",
    "print(converter) # record the options used\n",
    "\n",
    "encoded = converter.encode(train['Drug'][0])\n",
    "print(\"Encoded: %s\" % encoded)\n",
    "\n",
    "try:\n",
    "    decoded = converter.decode(encoded)\n",
    "except deepsmiles.DecodeError as e:\n",
    "    decoded = None\n",
    "    print(\"DecodeError! Error message was '%s'\" % e.message)\n",
    "\n",
    "if decoded:\n",
    "    print(\"Decoded: %s\" % decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caab513d-fbca-4ceb-80d7-2748de83948c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "\n",
    "def tokenize_smiles(df, smiles_col='Drug'):\n",
    "    df['Tokens'] = df[smiles_col].apply(lambda x: _tokenize_smiles_legacy(Chem.MolFromSmiles(str(x))))\n",
    "    return df\n",
    "\n",
    "def _tokenize_smiles_legacy(mol):\n",
    "\n",
    "    tokens = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        tokens.append(f\"A:{atom.GetSymbol()}\")\n",
    "    \n",
    "    for bond in mol.GetBonds():\n",
    "        begin, end, bond_type = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx(), bond.GetBondType()\n",
    "        tokens.append(f\"B:{begin}-{end}-{bond_type}\")\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a1901a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Drug_ID</th>\n",
       "      <th>Drug</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(-)-epicatechin</td>\n",
       "      <td>Oc1cc(O)c2c(c1)OC(c1ccc(O)c(O)c1)C(O)C2</td>\n",
       "      <td>-6.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(2E,4Z,8Z)-N-isobutyldodeca-2,4,10-triene-8 -y...</td>\n",
       "      <td>C/C=C\\C#CCC/C=C\\C=C\\C(=O)NCC(C)C</td>\n",
       "      <td>-3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>codeine</td>\n",
       "      <td>COc1ccc2c3c1O[C@H]1[C@@H](O)C=C[C@H]4[C@@H](C2...</td>\n",
       "      <td>-4.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>danazol</td>\n",
       "      <td>C#C[C@]1(O)CC[C@H]2[C@@H]3CCC4=Cc5oncc5C[C@]4(...</td>\n",
       "      <td>-4.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dexamethasone b D glucuronide</td>\n",
       "      <td>C[C@@H]1C[C@H]2[C@@H]3CCC4=CC(=O)C=C[C@]4(C)[C...</td>\n",
       "      <td>-6.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>13h</td>\n",
       "      <td>CN1C(=O)CC(N2CCCN(CCCN3c4ccccc4CCc4ccc(C(=O)O)...</td>\n",
       "      <td>-5.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>(Z)-19f</td>\n",
       "      <td>CN1C(=O)CC(N2CCCN(CC/C=C3/c4ccccc4CCc4ccc(CC(=...</td>\n",
       "      <td>-5.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>Ac-C8-Enk-NH (3)</td>\n",
       "      <td>CCCCCC[C@H](NC(C)=O)C(=O)N[C@@H](Cc1ccc(O)cc1)...</td>\n",
       "      <td>-5.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>Apometzgerin (2)</td>\n",
       "      <td>COc1cc(-c2cc(=O)c3c(O)cc(O)cc3o2)cc(O)c1OC</td>\n",
       "      <td>-4.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>Cycloheximide</td>\n",
       "      <td>C[C@H]1C[C@H](C)C(=O)[C@H]([C@H](O)CC2CC(=O)NC...</td>\n",
       "      <td>-4.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>637 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Drug_ID  \\\n",
       "0                                      (-)-epicatechin   \n",
       "1    (2E,4Z,8Z)-N-isobutyldodeca-2,4,10-triene-8 -y...   \n",
       "2                                              codeine   \n",
       "3                                              danazol   \n",
       "4                        dexamethasone b D glucuronide   \n",
       "..                                                 ...   \n",
       "632                                                13h   \n",
       "633                                            (Z)-19f   \n",
       "634                                   Ac-C8-Enk-NH (3)   \n",
       "635                                   Apometzgerin (2)   \n",
       "636                                      Cycloheximide   \n",
       "\n",
       "                                                  Drug     Y  \n",
       "0              Oc1cc(O)c2c(c1)OC(c1ccc(O)c(O)c1)C(O)C2 -6.22  \n",
       "1                     C/C=C\\C#CCC/C=C\\C=C\\C(=O)NCC(C)C -3.86  \n",
       "2    COc1ccc2c3c1O[C@H]1[C@@H](O)C=C[C@H]4[C@@H](C2... -4.09  \n",
       "3    C#C[C@]1(O)CC[C@H]2[C@@H]3CCC4=Cc5oncc5C[C@]4(... -4.84  \n",
       "4    C[C@@H]1C[C@H]2[C@@H]3CCC4=CC(=O)C=C[C@]4(C)[C... -6.12  \n",
       "..                                                 ...   ...  \n",
       "632  CN1C(=O)CC(N2CCCN(CCCN3c4ccccc4CCc4ccc(C(=O)O)... -5.36  \n",
       "633  CN1C(=O)CC(N2CCCN(CC/C=C3/c4ccccc4CCc4ccc(CC(=... -5.32  \n",
       "634  CCCCCC[C@H](NC(C)=O)C(=O)N[C@@H](Cc1ccc(O)cc1)... -5.97  \n",
       "635         COc1cc(-c2cc(=O)c3c(O)cc(O)cc3o2)cc(O)c1OC -4.95  \n",
       "636  C[C@H]1C[C@H](C)C(=O)[C@H]([C@H](O)CC2CC(=O)NC... -4.84  \n",
       "\n",
       "[637 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5098916b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "df = tokenize_smiles(df)\n",
    "\n",
    "train = tokenize_smiles(train)\n",
    "test = tokenize_smiles(test)\n",
    "valid = tokenize_smiles(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d203476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Drug_ID</th>\n",
       "      <th>Drug</th>\n",
       "      <th>Y</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(-)-epicatechin</td>\n",
       "      <td>Oc1cc(O)c2c(c1)OC(c1ccc(O)c(O)c1)C(O)C2</td>\n",
       "      <td>-6.220000</td>\n",
       "      <td>[A:O, A:C, A:C, A:C, A:O, A:C, A:C, A:C, A:O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(2E,4Z,8Z)-N-isobutyldodeca-2,4,10-triene-8 -y...</td>\n",
       "      <td>C/C=C\\C#CCC/C=C\\C=C\\C(=O)NCC(C)C</td>\n",
       "      <td>-3.860000</td>\n",
       "      <td>[A:C, A:C, A:C, A:C, A:C, A:C, A:C, A:C, A:C, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>codeine</td>\n",
       "      <td>COc1ccc2c3c1O[C@H]1[C@@H](O)C=C[C@H]4[C@@H](C2...</td>\n",
       "      <td>-4.090000</td>\n",
       "      <td>[A:C, A:O, A:C, A:C, A:C, A:C, A:C, A:C, A:O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>danazol</td>\n",
       "      <td>C#C[C@]1(O)CC[C@H]2[C@@H]3CCC4=Cc5oncc5C[C@]4(...</td>\n",
       "      <td>-4.840000</td>\n",
       "      <td>[A:C, A:C, A:C, A:O, A:C, A:C, A:C, A:C, A:C, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dexamethasone b D glucuronide</td>\n",
       "      <td>C[C@@H]1C[C@H]2[C@@H]3CCC4=CC(=O)C=C[C@]4(C)[C...</td>\n",
       "      <td>-6.120000</td>\n",
       "      <td>[A:C, A:C, A:C, A:C, A:C, A:C, A:C, A:C, A:C, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>atropine</td>\n",
       "      <td>CN1[C@H]2CC[C@@H]1CC(OC(=O)C(CO)c1ccccc1)C2</td>\n",
       "      <td>-4.700000</td>\n",
       "      <td>[A:C, A:N, A:C, A:C, A:C, A:C, A:C, A:C, A:O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>Guanabenz</td>\n",
       "      <td>NC(N)=NN=Cc1c(Cl)cccc1Cl</td>\n",
       "      <td>-4.330000</td>\n",
       "      <td>[A:N, A:C, A:N, A:N, A:N, A:C, A:C, A:C, A:Cl,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>4</td>\n",
       "      <td>CN(C(=O)[C@H](Cc1ccc(CN)cc1)NS(=O)(=O)c1ccc2cc...</td>\n",
       "      <td>-4.958607</td>\n",
       "      <td>[A:C, A:N, A:C, A:O, A:C, A:C, A:C, A:C, A:C, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>20(S)-camptothecin (CPT)</td>\n",
       "      <td>CC[C@]1(O)C(=O)OCc2c1cc1n(c2=O)-c2cc3ccccc3nc2C1</td>\n",
       "      <td>-4.331849</td>\n",
       "      <td>[A:C, A:C, A:C, A:O, A:C, A:O, A:O, A:C, A:C, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>hexapeptide 07</td>\n",
       "      <td>C[C@@H]1NC(=O)[C@H](C)NC(=O)[C@@H](C)NC(=O)[C@...</td>\n",
       "      <td>-5.820000</td>\n",
       "      <td>[A:C, A:C, A:N, A:C, A:O, A:C, A:C, A:N, A:C, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>910 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Drug_ID  \\\n",
       "0                                      (-)-epicatechin   \n",
       "1    (2E,4Z,8Z)-N-isobutyldodeca-2,4,10-triene-8 -y...   \n",
       "2                                              codeine   \n",
       "3                                              danazol   \n",
       "4                        dexamethasone b D glucuronide   \n",
       "..                                                 ...   \n",
       "905                                           atropine   \n",
       "906                                          Guanabenz   \n",
       "907                                                  4   \n",
       "908                           20(S)-camptothecin (CPT)   \n",
       "909                                     hexapeptide 07   \n",
       "\n",
       "                                                  Drug         Y  \\\n",
       "0              Oc1cc(O)c2c(c1)OC(c1ccc(O)c(O)c1)C(O)C2 -6.220000   \n",
       "1                     C/C=C\\C#CCC/C=C\\C=C\\C(=O)NCC(C)C -3.860000   \n",
       "2    COc1ccc2c3c1O[C@H]1[C@@H](O)C=C[C@H]4[C@@H](C2... -4.090000   \n",
       "3    C#C[C@]1(O)CC[C@H]2[C@@H]3CCC4=Cc5oncc5C[C@]4(... -4.840000   \n",
       "4    C[C@@H]1C[C@H]2[C@@H]3CCC4=CC(=O)C=C[C@]4(C)[C... -6.120000   \n",
       "..                                                 ...       ...   \n",
       "905        CN1[C@H]2CC[C@@H]1CC(OC(=O)C(CO)c1ccccc1)C2 -4.700000   \n",
       "906                           NC(N)=NN=Cc1c(Cl)cccc1Cl -4.330000   \n",
       "907  CN(C(=O)[C@H](Cc1ccc(CN)cc1)NS(=O)(=O)c1ccc2cc... -4.958607   \n",
       "908   CC[C@]1(O)C(=O)OCc2c1cc1n(c2=O)-c2cc3ccccc3nc2C1 -4.331849   \n",
       "909  C[C@@H]1NC(=O)[C@H](C)NC(=O)[C@@H](C)NC(=O)[C@... -5.820000   \n",
       "\n",
       "                                                Tokens  \n",
       "0    [A:O, A:C, A:C, A:C, A:O, A:C, A:C, A:C, A:O, ...  \n",
       "1    [A:C, A:C, A:C, A:C, A:C, A:C, A:C, A:C, A:C, ...  \n",
       "2    [A:C, A:O, A:C, A:C, A:C, A:C, A:C, A:C, A:O, ...  \n",
       "3    [A:C, A:C, A:C, A:O, A:C, A:C, A:C, A:C, A:C, ...  \n",
       "4    [A:C, A:C, A:C, A:C, A:C, A:C, A:C, A:C, A:C, ...  \n",
       "..                                                 ...  \n",
       "905  [A:C, A:N, A:C, A:C, A:C, A:C, A:C, A:C, A:O, ...  \n",
       "906  [A:N, A:C, A:N, A:N, A:N, A:C, A:C, A:C, A:Cl,...  \n",
       "907  [A:C, A:N, A:C, A:O, A:C, A:C, A:C, A:C, A:C, ...  \n",
       "908  [A:C, A:C, A:C, A:O, A:C, A:O, A:O, A:C, A:C, ...  \n",
       "909  [A:C, A:C, A:N, A:C, A:O, A:C, A:C, A:N, A:C, ...  \n",
       "\n",
       "[910 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bbc33f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90ea34d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_string(lst):\n",
    "    return ' '.join(lst)\n",
    "\n",
    "# Apply the function to the column\n",
    "train['Tokens2'] = train['Tokens'].apply(convert_to_string)\n",
    "test['Tokens2'] = test['Tokens'].apply(convert_to_string)\n",
    "valid['Tokens2'] = valid['Tokens'].apply(convert_to_string)\n",
    "df['Tokens2'] = df['Tokens'].apply(convert_to_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e7c7bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "\n",
    "\n",
    "# def custom_vectorizer(sequence, elements):\n",
    "#     counts = Counter(sequence)\n",
    "#     vector = [counts[element] for element in elements]\n",
    "#     return np.array(vector)\n",
    "\n",
    "\n",
    "# def apply_custom_vectorizer(df, column_name):\n",
    "#     # Extract unique elements from the specified column\n",
    "#     unique_elements = sorted(set([element for sublist in df[column_name] for element in sublist]))\n",
    "    \n",
    "#     # Vectorize each sequence in the specified column\n",
    "#     vectorized_sequences = [custom_vectorizer(seq, unique_elements) for seq in df[column_name]]\n",
    "    \n",
    "#     # Create a DataFrame with the vectorized sequences\n",
    "#     vectorized_df = pd.DataFrame(vectorized_sequences, columns=unique_elements)\n",
    "    \n",
    "#     # Concatenate the vectorized DataFrame with the original DataFrame\n",
    "#     df = pd.concat([df, vectorized_df], axis=1)\n",
    "    \n",
    "#     return df\n",
    "\n",
    "# # Apply the custom vectorizer to the 'sequences' column\n",
    "# train = apply_custom_vectorizer(train, 'Tokens')\n",
    "# test = apply_custom_vectorizer(test, 'Tokens')\n",
    "# valid = apply_custom_vectorizer(valid, 'Tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdf80995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = train.drop(['Drug_ID', 'Drug', 'Y', 'Tokens'], axis=1)\n",
    "# y = np.array(train['Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a03d1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization and Vectorization\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "# vectorizer = TfidfVectorizer()\n",
    "\n",
    "\n",
    "X = vectorizer.fit_transform(df['Tokens2'])\n",
    "\n",
    "y = np.array(df['Y'])\n",
    "\n",
    "# X_test = vectorizer.fit_transform(test['Tokens'])\n",
    "# y_test = np.array(test['Y'])\n",
    "\n",
    "# X_valid = vectorizer.fit_transform(valid['Tokens'])\n",
    "# y_valid = np.array(valid['Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20f655a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Drug_ID</th>\n",
       "      <th>Drug</th>\n",
       "      <th>Y</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Tokens2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(-)-epicatechin</td>\n",
       "      <td>Oc1cc(O)c2c(c1)OC(c1ccc(O)c(O)c1)C(O)C2</td>\n",
       "      <td>-6.220000</td>\n",
       "      <td>[A:O, A:C, A:C, A:C, A:O, A:C, A:C, A:C, A:O, ...</td>\n",
       "      <td>A:O A:C A:C A:C A:O A:C A:C A:C A:O A:C A:C A:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(2E,4Z,8Z)-N-isobutyldodeca-2,4,10-triene-8 -y...</td>\n",
       "      <td>C/C=C\\C#CCC/C=C\\C=C\\C(=O)NCC(C)C</td>\n",
       "      <td>-3.860000</td>\n",
       "      <td>[A:C, A:C, A:C, A:C, A:C, A:C, A:C, A:C, A:C, ...</td>\n",
       "      <td>A:C A:C A:C A:C A:C A:C A:C A:C A:C A:C A:C A:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>codeine</td>\n",
       "      <td>COc1ccc2c3c1O[C@H]1[C@@H](O)C=C[C@H]4[C@@H](C2...</td>\n",
       "      <td>-4.090000</td>\n",
       "      <td>[A:C, A:O, A:C, A:C, A:C, A:C, A:C, A:C, A:O, ...</td>\n",
       "      <td>A:C A:O A:C A:C A:C A:C A:C A:C A:O A:C A:C A:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>danazol</td>\n",
       "      <td>C#C[C@]1(O)CC[C@H]2[C@@H]3CCC4=Cc5oncc5C[C@]4(...</td>\n",
       "      <td>-4.840000</td>\n",
       "      <td>[A:C, A:C, A:C, A:O, A:C, A:C, A:C, A:C, A:C, ...</td>\n",
       "      <td>A:C A:C A:C A:O A:C A:C A:C A:C A:C A:C A:C A:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dexamethasone b D glucuronide</td>\n",
       "      <td>C[C@@H]1C[C@H]2[C@@H]3CCC4=CC(=O)C=C[C@]4(C)[C...</td>\n",
       "      <td>-6.120000</td>\n",
       "      <td>[A:C, A:C, A:C, A:C, A:C, A:C, A:C, A:C, A:C, ...</td>\n",
       "      <td>A:C A:C A:C A:C A:C A:C A:C A:C A:C A:C A:O A:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>atropine</td>\n",
       "      <td>CN1[C@H]2CC[C@@H]1CC(OC(=O)C(CO)c1ccccc1)C2</td>\n",
       "      <td>-4.700000</td>\n",
       "      <td>[A:C, A:N, A:C, A:C, A:C, A:C, A:C, A:C, A:O, ...</td>\n",
       "      <td>A:C A:N A:C A:C A:C A:C A:C A:C A:O A:C A:O A:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>Guanabenz</td>\n",
       "      <td>NC(N)=NN=Cc1c(Cl)cccc1Cl</td>\n",
       "      <td>-4.330000</td>\n",
       "      <td>[A:N, A:C, A:N, A:N, A:N, A:C, A:C, A:C, A:Cl,...</td>\n",
       "      <td>A:N A:C A:N A:N A:N A:C A:C A:C A:Cl A:C A:C A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>4</td>\n",
       "      <td>CN(C(=O)[C@H](Cc1ccc(CN)cc1)NS(=O)(=O)c1ccc2cc...</td>\n",
       "      <td>-4.958607</td>\n",
       "      <td>[A:C, A:N, A:C, A:O, A:C, A:C, A:C, A:C, A:C, ...</td>\n",
       "      <td>A:C A:N A:C A:O A:C A:C A:C A:C A:C A:C A:C A:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>20(S)-camptothecin (CPT)</td>\n",
       "      <td>CC[C@]1(O)C(=O)OCc2c1cc1n(c2=O)-c2cc3ccccc3nc2C1</td>\n",
       "      <td>-4.331849</td>\n",
       "      <td>[A:C, A:C, A:C, A:O, A:C, A:O, A:O, A:C, A:C, ...</td>\n",
       "      <td>A:C A:C A:C A:O A:C A:O A:O A:C A:C A:C A:C A:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>hexapeptide 07</td>\n",
       "      <td>C[C@@H]1NC(=O)[C@H](C)NC(=O)[C@@H](C)NC(=O)[C@...</td>\n",
       "      <td>-5.820000</td>\n",
       "      <td>[A:C, A:C, A:N, A:C, A:O, A:C, A:C, A:N, A:C, ...</td>\n",
       "      <td>A:C A:C A:N A:C A:O A:C A:C A:N A:C A:O A:C A:...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>910 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Drug_ID  \\\n",
       "0                                      (-)-epicatechin   \n",
       "1    (2E,4Z,8Z)-N-isobutyldodeca-2,4,10-triene-8 -y...   \n",
       "2                                              codeine   \n",
       "3                                              danazol   \n",
       "4                        dexamethasone b D glucuronide   \n",
       "..                                                 ...   \n",
       "905                                           atropine   \n",
       "906                                          Guanabenz   \n",
       "907                                                  4   \n",
       "908                           20(S)-camptothecin (CPT)   \n",
       "909                                     hexapeptide 07   \n",
       "\n",
       "                                                  Drug         Y  \\\n",
       "0              Oc1cc(O)c2c(c1)OC(c1ccc(O)c(O)c1)C(O)C2 -6.220000   \n",
       "1                     C/C=C\\C#CCC/C=C\\C=C\\C(=O)NCC(C)C -3.860000   \n",
       "2    COc1ccc2c3c1O[C@H]1[C@@H](O)C=C[C@H]4[C@@H](C2... -4.090000   \n",
       "3    C#C[C@]1(O)CC[C@H]2[C@@H]3CCC4=Cc5oncc5C[C@]4(... -4.840000   \n",
       "4    C[C@@H]1C[C@H]2[C@@H]3CCC4=CC(=O)C=C[C@]4(C)[C... -6.120000   \n",
       "..                                                 ...       ...   \n",
       "905        CN1[C@H]2CC[C@@H]1CC(OC(=O)C(CO)c1ccccc1)C2 -4.700000   \n",
       "906                           NC(N)=NN=Cc1c(Cl)cccc1Cl -4.330000   \n",
       "907  CN(C(=O)[C@H](Cc1ccc(CN)cc1)NS(=O)(=O)c1ccc2cc... -4.958607   \n",
       "908   CC[C@]1(O)C(=O)OCc2c1cc1n(c2=O)-c2cc3ccccc3nc2C1 -4.331849   \n",
       "909  C[C@@H]1NC(=O)[C@H](C)NC(=O)[C@@H](C)NC(=O)[C@... -5.820000   \n",
       "\n",
       "                                                Tokens  \\\n",
       "0    [A:O, A:C, A:C, A:C, A:O, A:C, A:C, A:C, A:O, ...   \n",
       "1    [A:C, A:C, A:C, A:C, A:C, A:C, A:C, A:C, A:C, ...   \n",
       "2    [A:C, A:O, A:C, A:C, A:C, A:C, A:C, A:C, A:O, ...   \n",
       "3    [A:C, A:C, A:C, A:O, A:C, A:C, A:C, A:C, A:C, ...   \n",
       "4    [A:C, A:C, A:C, A:C, A:C, A:C, A:C, A:C, A:C, ...   \n",
       "..                                                 ...   \n",
       "905  [A:C, A:N, A:C, A:C, A:C, A:C, A:C, A:C, A:O, ...   \n",
       "906  [A:N, A:C, A:N, A:N, A:N, A:C, A:C, A:C, A:Cl,...   \n",
       "907  [A:C, A:N, A:C, A:O, A:C, A:C, A:C, A:C, A:C, ...   \n",
       "908  [A:C, A:C, A:C, A:O, A:C, A:O, A:O, A:C, A:C, ...   \n",
       "909  [A:C, A:C, A:N, A:C, A:O, A:C, A:C, A:N, A:C, ...   \n",
       "\n",
       "                                               Tokens2  \n",
       "0    A:O A:C A:C A:C A:O A:C A:C A:C A:O A:C A:C A:...  \n",
       "1    A:C A:C A:C A:C A:C A:C A:C A:C A:C A:C A:C A:...  \n",
       "2    A:C A:O A:C A:C A:C A:C A:C A:C A:O A:C A:C A:...  \n",
       "3    A:C A:C A:C A:O A:C A:C A:C A:C A:C A:C A:C A:...  \n",
       "4    A:C A:C A:C A:C A:C A:C A:C A:C A:C A:C A:O A:...  \n",
       "..                                                 ...  \n",
       "905  A:C A:N A:C A:C A:C A:C A:C A:C A:O A:C A:O A:...  \n",
       "906  A:N A:C A:N A:N A:N A:C A:C A:C A:Cl A:C A:C A...  \n",
       "907  A:C A:N A:C A:O A:C A:C A:C A:C A:C A:C A:C A:...  \n",
       "908  A:C A:C A:C A:O A:C A:O A:O A:C A:C A:C A:C A:...  \n",
       "909  A:C A:C A:N A:C A:O A:C A:C A:N A:C A:O A:C A:...  \n",
       "\n",
       "[910 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3530471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Oc1cc(O)c2c(c1)OC(c1ccc(O)c(O)c1)C(O)C2'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4375992e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Draw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m mol \u001b[38;5;241m=\u001b[39m Chem\u001b[38;5;241m.\u001b[39mMolFromSmiles(smiles)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mol \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m----> 8\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mDraw\u001b[49m\u001b[38;5;241m.\u001b[39mMolToImage(mol)\n\u001b[1;32m      9\u001b[0m     img_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmolecule_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     10\u001b[0m     img\u001b[38;5;241m.\u001b[39msave(img_path)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Draw' is not defined"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, Image\n",
    "\n",
    "# Assuming df is your pandas DataFrame\n",
    "for i in range(len(df)):\n",
    "    smiles = df.iloc[i, 1]\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is not None:\n",
    "        img = Draw.MolToImage(mol)\n",
    "        img_path = f'molecule_{i}.png'\n",
    "        img.save(img_path)\n",
    "        print(f'Saved {img_path}')\n",
    "        display(Image(filename=img_path))\n",
    "    else:\n",
    "        print(f'Invalid SMILES at row {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aaa3ceb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'molecule_0.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load a specific image\u001b[39;00m\n\u001b[1;32m      4\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmolecule_0.png\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Change this to the path of the image you want to load\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m image\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/PIL/Image.py:3218\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3215\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[1;32m   3217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[0;32m-> 3218\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3219\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   3221\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'molecule_0.png'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Load a specific image\n",
    "image_path = 'molecule_0.png'  # Change this to the path of the image you want to load\n",
    "image = Image.open(image_path)\n",
    "image.show()  # This will open the image using the default image viewer on your system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "ac3ae97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_dir, labels, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "        # Load image paths\n",
    "        self.image_paths = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.png')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Example labels array (replace this with your actual labels)\n",
    "labels = df['Y']\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to a fixed size\n",
    "    transforms.ToTensor(),          # Convert images to tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize images\n",
    "])\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Define your dataset\n",
    "dataset = CustomDataset(data_dir=current_directory, labels=labels, transform=transform)\n",
    "\n",
    "# Define data loader\n",
    "batch_size = 32\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Iterate over the data loader\n",
    "for images, labels in data_loader:\n",
    "    # Process batch in your CNN model\n",
    "    # 'images' will contain a tensor of shape (batch_size, channels, height, width)\n",
    "    # 'labels' will contain the corresponding labels\n",
    "    pass  # Replace this with your CNN model processing code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "83a3da54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x327ab35e0>"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "8db96e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 15.6310\n",
      "Epoch [2/100], Loss: 0.7391\n",
      "Epoch [3/100], Loss: 0.6077\n",
      "Epoch [4/100], Loss: 0.6030\n",
      "Epoch [5/100], Loss: 0.5955\n",
      "Epoch [6/100], Loss: 0.5791\n",
      "Epoch [7/100], Loss: 0.5738\n",
      "Epoch [8/100], Loss: 0.6087\n",
      "Epoch [9/100], Loss: 0.5105\n",
      "Epoch [10/100], Loss: 0.4544\n",
      "Epoch [11/100], Loss: 0.3880\n",
      "Epoch [12/100], Loss: 0.3438\n",
      "Epoch [13/100], Loss: 0.3290\n",
      "Epoch [14/100], Loss: 0.2579\n",
      "Epoch [15/100], Loss: 0.2212\n",
      "Epoch [16/100], Loss: 0.1760\n",
      "Epoch [17/100], Loss: 0.1594\n",
      "Epoch [18/100], Loss: 0.1430\n",
      "Epoch [19/100], Loss: 0.1255\n",
      "Epoch [20/100], Loss: 0.1405\n",
      "Epoch [21/100], Loss: 0.1212\n",
      "Epoch [22/100], Loss: 0.0965\n",
      "Epoch [23/100], Loss: 0.0907\n",
      "Epoch [24/100], Loss: 0.0876\n",
      "Epoch [25/100], Loss: 0.0794\n",
      "Epoch [26/100], Loss: 0.0738\n",
      "Epoch [27/100], Loss: 0.0715\n",
      "Epoch [28/100], Loss: 0.0698\n",
      "Epoch [29/100], Loss: 0.0734\n",
      "Epoch [30/100], Loss: 0.0703\n",
      "Epoch [31/100], Loss: 0.0633\n",
      "Epoch [32/100], Loss: 0.0652\n",
      "Epoch [33/100], Loss: 0.0860\n",
      "Epoch [34/100], Loss: 0.0686\n",
      "Epoch [35/100], Loss: 0.0627\n",
      "Epoch [36/100], Loss: 0.0613\n",
      "Epoch [37/100], Loss: 0.0565\n",
      "Epoch [38/100], Loss: 0.0472\n",
      "Epoch [39/100], Loss: 0.0459\n",
      "Epoch [40/100], Loss: 0.0456\n",
      "Epoch [41/100], Loss: 0.0484\n",
      "Epoch [42/100], Loss: 0.0448\n",
      "Epoch [43/100], Loss: 0.0465\n",
      "Epoch [44/100], Loss: 0.0466\n",
      "Epoch [45/100], Loss: 0.0536\n",
      "Epoch [46/100], Loss: 0.0775\n",
      "Epoch [47/100], Loss: 0.0520\n",
      "Epoch [48/100], Loss: 0.0478\n",
      "Epoch [49/100], Loss: 0.0508\n",
      "Epoch [50/100], Loss: 0.0579\n",
      "Epoch [51/100], Loss: 0.0535\n",
      "Epoch [52/100], Loss: 0.0437\n",
      "Epoch [53/100], Loss: 0.0532\n",
      "Epoch [54/100], Loss: 0.0461\n",
      "Epoch [55/100], Loss: 0.0463\n",
      "Epoch [56/100], Loss: 0.0480\n",
      "Epoch [57/100], Loss: 0.0444\n",
      "Epoch [58/100], Loss: 0.0433\n",
      "Epoch [59/100], Loss: 0.0363\n",
      "Epoch [60/100], Loss: 0.0405\n",
      "Epoch [61/100], Loss: 0.0401\n",
      "Epoch [62/100], Loss: 0.0506\n",
      "Epoch [63/100], Loss: 0.0698\n",
      "Epoch [64/100], Loss: 0.0565\n",
      "Epoch [65/100], Loss: 0.0396\n",
      "Epoch [66/100], Loss: 0.0412\n",
      "Epoch [67/100], Loss: 0.0475\n",
      "Epoch [68/100], Loss: 0.0497\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[334], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     37\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, y \u001b[38;5;129;01min\u001b[39;00m data_loader:\n\u001b[1;32m     39\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     40\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(images)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[332], line 21\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m     20\u001b[0m     img_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_paths[idx]\n\u001b[0;32m---> 21\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[1;32m     24\u001b[0m         image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(image)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/PIL/Image.py:3218\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3215\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[1;32m   3217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[0;32m-> 3218\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3219\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   3221\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(64 * 28 * 28, 512)\n",
    "        self.fc2 = nn.Linear(512, 1)  # Output is a single value for prediction\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 64 * 28 * 28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "model = CNN()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()  # Mean Squared Error loss for regression\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, y in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        outputs = outputs.float()  # Convert to float if the model output is double\n",
    "        loss = criterion(outputs, y.view(-1, 1).float())  # Reshape y to match output shape\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    train_loss = running_loss / len(data_loader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "d38c43ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 2.2754\n",
      "Epoch [2/100], Loss: 0.6699\n",
      "Epoch [3/100], Loss: 0.6436\n",
      "Epoch [4/100], Loss: 0.6555\n",
      "Epoch [5/100], Loss: 0.6410\n",
      "Epoch [6/100], Loss: 0.5698\n",
      "Epoch [7/100], Loss: 0.5523\n",
      "Epoch [8/100], Loss: 0.5147\n",
      "Epoch [9/100], Loss: 0.5446\n",
      "Epoch [10/100], Loss: 0.4831\n",
      "Epoch [11/100], Loss: 0.4302\n",
      "Epoch [12/100], Loss: 0.4382\n",
      "Epoch [13/100], Loss: 0.4079\n",
      "Epoch [14/100], Loss: 0.4410\n",
      "Epoch [15/100], Loss: 0.4245\n",
      "Epoch [16/100], Loss: 0.3909\n",
      "Epoch [17/100], Loss: 0.3677\n",
      "Epoch [18/100], Loss: 0.3626\n",
      "Epoch [19/100], Loss: 0.3077\n",
      "Epoch [20/100], Loss: 0.2849\n",
      "Epoch [21/100], Loss: 0.3425\n",
      "Epoch [22/100], Loss: 0.3253\n",
      "Epoch [23/100], Loss: 0.2674\n",
      "Epoch [24/100], Loss: 0.3120\n",
      "Epoch [25/100], Loss: 0.2791\n",
      "Epoch [26/100], Loss: 0.2458\n",
      "Epoch [27/100], Loss: 0.2411\n",
      "Epoch [28/100], Loss: 0.2335\n",
      "Epoch [29/100], Loss: 0.2193\n",
      "Epoch [30/100], Loss: 0.2331\n",
      "Epoch [31/100], Loss: 0.2386\n",
      "Epoch [32/100], Loss: 0.2199\n",
      "Epoch [33/100], Loss: 0.2404\n",
      "Epoch [34/100], Loss: 0.2448\n",
      "Epoch [35/100], Loss: 0.2330\n",
      "Epoch [36/100], Loss: 0.2151\n",
      "Epoch [37/100], Loss: 0.2427\n",
      "Epoch [38/100], Loss: 0.2271\n",
      "Epoch [39/100], Loss: 0.2084\n",
      "Epoch [40/100], Loss: 0.2093\n",
      "Epoch [41/100], Loss: 0.1846\n",
      "Epoch [42/100], Loss: 0.1807\n",
      "Epoch [43/100], Loss: 0.2263\n",
      "Epoch [44/100], Loss: 0.1966\n",
      "Epoch [45/100], Loss: 0.1877\n",
      "Epoch [46/100], Loss: 0.1843\n",
      "Epoch [47/100], Loss: 0.2015\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[335], line 43\u001b[0m\n\u001b[1;32m     41\u001b[0m outputs \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# Convert to float if the model output is double\u001b[39;00m\n\u001b[1;32m     42\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, y\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat())  \u001b[38;5;66;03m# Reshape y to match output shape\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     45\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(64 * 28 * 28, 512)\n",
    "        self.fc2 = nn.Linear(512, 1)  # Output is a single value for prediction\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 64 * 28 * 28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "model = CNN()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.L1Loss()  # Mean Absolute Error loss for regression\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, y in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        outputs = outputs.float()  # Convert to float if the model output is double\n",
    "        loss = criterion(outputs, y.view(-1, 1).float())  # Reshape y to match output shape\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    train_loss = running_loss / len(data_loader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d55232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "77314f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Test Set: 0.5690\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train.toarray()\n",
    "X_test = X_test.toarray()\n",
    "\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "# X_train_tensor = torch.tensor(X_train.toarray(), dtype=torch.float32)\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "# X_test_tensor = torch.tensor(X_test.toarray(), dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Define the LSTM model\n",
    "class LSTMPredictor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMPredictor, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "#         self.dropout = nn.Dropout(dropout)\n",
    "#         self.batch_norm = nn.BatchNorm1d(hidden_size)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden and cell states\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))  \n",
    "#         out = self.dropout(out)\n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "input_size = X_train_tensor.shape[1]\n",
    "hidden_size = 256\n",
    "num_layers = 2\n",
    "output_size = 1  # Output a single value for prediction\n",
    "\n",
    "model = LSTMPredictor(input_size, hidden_size, num_layers, output_size)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(0, len(X_train_tensor), batch_size):\n",
    "        inputs = X_train_tensor[i:i+batch_size].unsqueeze(1)  # Adjusting input dimensions\n",
    "        labels = y_train_tensor[i:i+batch_size]\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 2 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(X_train_tensor)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Test the model\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test_tensor.unsqueeze(1))  # Adjusting input dimensions\n",
    "    mse = criterion(outputs.squeeze(), y_test_tensor)\n",
    "    print(f'Mean Squared Error on Test Set: {mse.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bafaad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d21071e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9950ea12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fc4667",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33134928",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90420336",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc53106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebc0108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee6aeb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21ef07c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "92ff8105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Test Set: 0.6355\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X_train, X_test, y_train, and y_test are defined\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train.toarray(), dtype=torch.long)  # Assuming input data is categorical and needs embedding\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test.toarray(), dtype=torch.long)    # Assuming input data is categorical and needs embedding\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Define the LSTM model\n",
    "class LSTMPredictor(nn.Module):\n",
    "    def __init__(self, input_size, embedding_dim, hidden_size, num_layers, output_size):\n",
    "        super(LSTMPredictor, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_size, embedding_dim)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        # Initialize hidden and cell states\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(embedded, (h0, c0))\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "input_size = 150  # Assuming X_train contains categorical data\n",
    "embedding_dim = 10  # Choose an appropriate embedding dimension\n",
    "hidden_size = 256\n",
    "num_layers = 3\n",
    "output_size = 1\n",
    "\n",
    "model = LSTMPredictor(input_size, embedding_dim, hidden_size, num_layers, output_size)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 50\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i in range(0, len(X_train_tensor), batch_size):\n",
    "        inputs = X_train_tensor[i:i+batch_size]  # No need to unsqueeze as embedding layer expects input in 2D\n",
    "        labels = y_train_tensor[i:i+batch_size]\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if (i+1) % 2 == 0:  # Print every 2nd step\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(X_train_tensor)}], Loss: {running_loss/2:.4f}')\n",
    "            running_loss = 0.0  # Reset running loss\n",
    "# Test the model\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test_tensor)\n",
    "    mse = criterion(outputs.squeeze(), y_test_tensor)\n",
    "    print(f'Mean Squared Error on Test Set: {mse.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30158399",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f10df4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ec4af8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8350c0b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dede76ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50770847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489f5fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c985a6c6-ed02-41b0-9896-2d809c16bfb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
